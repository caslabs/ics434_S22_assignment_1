{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview \n",
    "\n",
    "* In this assignment, you will practice some data wrangling functionality commonly used in real-world projects.\n",
    "\n",
    "* This assignment is designed around two dataset\n",
    "\n",
    "* The Medicaid Data per State  \n",
    "\n",
    "* IRS Statistics of Income (SOI) dataset\n",
    "\n",
    "\n",
    "* The final product of this assignment will be a table with medication cost per Medicaid enrollee per state. This dataset will allow us to answer such questions as:\n",
    "  * Which medications account for the bulk of a state's spending   \n",
    "  * Which medications are prescribed more frequently in one state than another.\n",
    "  * etc.\n",
    "\n",
    "* The following URLs provide the datasets required for this assignment:\n",
    "  * [medicaid_data.csv](https://www.dropbox.com/s/u6ctjqxnk0wxpbk/medicaid_data.csv?dl=1)\n",
    "  * [medicaid_enrollment.tsv](https://www.dropbox.com/s/969mohzhpu78r10/medicaid_enrollment.tsv?dl=1)\n",
    "  * [tax_data.csv](https://www.dropbox.com/s/zm37nu7vnirha4m/tax_data.csv?dl=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Instructions on answering the questions\n",
    "\n",
    "- Some of the questions below require that you only use methods or properties of a `DataFrame` or a `Series`. Therefore, any solution that uses a function that is not a method or property of `DataFrame` or `Series` will not be accepted, even when the solution yields an appropriate answer to the question.\n",
    "\n",
    "- For instance, if you are asked to find the number of entries in the DataFrame `tax_data ` using only the DataFrame's methods or properties, then `len(tax_data)` is not an acceptable solution since `len()` is not a `tax_data` method. The statements below are both correct answers:\n",
    "\n",
    "  - `info()` is a method `tax_data`\n",
    "  \n",
    "```python\n",
    "   \n",
    "    tax_data.info()\n",
    "```\n",
    "\n",
    "  or\n",
    "\n",
    "  - `shape` is a property of `tax_data`\n",
    "\n",
    "\n",
    "```python\n",
    "tax_data.shape\n",
    "```\n",
    "\n",
    "- Similarly, if you are asked to find to count the number of unique entries in the `STATEFIPS` column of the `tax_data` DataFrame, then solutions using set() or len() are not acceptable for the following reasons:\n",
    "\n",
    "- The solution below uses `set()` and `len()`, which are not `tax_data` methods\n",
    "\n",
    "```python\n",
    "len(set(tax_data[\"STATEFIPS\"]))\n",
    "```\n",
    "\n",
    "- The solution below uses `unique()`, which is a  `tax_data` method, but then counts the number of uniques entries using `len()` which is not `tax_data` method\n",
    "\n",
    "```python\n",
    "len(tax_data[\"STATEFIPS\"].unique())\n",
    "```\n",
    "\n",
    "\n",
    "- The statement below is an acceptable solution since it uses `nunique()` which is a method of the `Series` generated by indexing on a column of `tax_data` (`tax_data['STATEFIPS'])\n",
    "\n",
    "```python\n",
    "tax_data['STATEFIPS'].nunique()\n",
    "```\n",
    "\n",
    "\n",
    "- Chaining methods and properties is encouraged if it does not cause ambiguity \n",
    "\n",
    "- For instance, to identify whether a value is part of the index, write the following:\n",
    "\n",
    "```python\n",
    "tax_data.index.contains(99999)\n",
    "```\n",
    "\n",
    "- Rather than:\n",
    "\n",
    "```python\n",
    "9999 in tax_data.index\n",
    "```\n",
    "\n",
    "- You can only import `pandas` and `numpy`\n",
    "\n",
    "- If you are not explicitly asked to only use methods or properties of a `DataFrame` or a `Series`, then any solution that does not rely on external modules will be accepted.\n",
    "\n",
    "- __Important__: Provide the exact statement(s) used to answer each question\n",
    "\n",
    "- Unless otherwise specified, each cell can contain multiple lines of code\n",
    "\n",
    "* Finally, note that not all the functions necessary for answering the questions below were covered in class. As such, assuming you are using Jupyter Notebooks, I suggest you use `.SHIFT+TAB` on objects liberally to see which methods and properties are available on objects. If you are unsure what a method does, use `SHIFT+TAB` twice to invoke the `docstring`, or documentation for that function. This is not only a good way to see which functionality can be used to answer the questions below but also a great way to familiarize yourself with the plethora of functionality available through the `pandas` package. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and exploring the tax data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas and numpy using their appropriate alias here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Load the IRS Statistics of Income (SOI) dataset (`tax_data.csv`) into a `DataFrame` called `tax_data`. This file can be downloaded from the `URL` provided above.\n",
    "\n",
    "* This file `tax_data.csv` was preprocessed from the original file I obtained at the following URL:\n",
    "  * [15zpallagi.csv](https://www.irs.gov/pub/irs-soi/15zpallagi.csv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "tax_data = pd.read_csv('tax_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use a `tax_data` method or property to display the first eight (8) rows of the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   STATEFIPS STATE  zipcode  agi_stub        N1     mars1     MARS2     MARS4  \\\n0          1    AL        0         1  836320.0  481570.0  109790.0  233260.0   \n1          1    AL        0         2  494830.0  206630.0  146250.0  129390.0   \n2          1    AL        0         3  261250.0   80720.0  139280.0   36130.0   \n3          1    AL        0         4  166690.0   28510.0  124650.0   10630.0   \n4          1    AL        0         5  212660.0   19520.0  184320.0    4830.0   \n5          1    AL        0         6   55360.0    2950.0   49260.0     350.0   \n6          1    AL    35004         1    1490.0     970.0     230.0     280.0   \n7          1    AL    35004         2    1350.0     630.0     360.0     300.0   \n\n       PREP         N2  ...    N10300     A10300   N85530   A85530   N85300  \\\n0  455560.0  1356760.0  ...  373410.0   328469.0      0.0      0.0      0.0   \n1  275920.0  1010990.0  ...  395880.0   965011.0      0.0      0.0      0.0   \n2  155100.0   583910.0  ...  251490.0  1333418.0      0.0      0.0      0.0   \n3   99950.0   423990.0  ...  165320.0  1414283.0      0.0      0.0      0.0   \n4  126860.0   589490.0  ...  212000.0  3820152.0    420.0    168.0     60.0   \n5   41410.0   160530.0  ...   55300.0  6027793.0  22090.0  39519.0  27550.0   \n6     700.0     2160.0  ...     690.0      610.0      0.0      0.0      0.0   \n7     610.0     2540.0  ...    1140.0     3019.0      0.0      0.0      0.0   \n\n    A85300   N11901    A11901    N11902     A11902  \n0      0.0  61920.0   48150.0  732670.0  1933120.0  \n1      0.0  73720.0  107304.0  415410.0  1187403.0  \n2      0.0  64200.0  139598.0  193030.0   536699.0  \n3      0.0  45460.0  128823.0  116440.0   377177.0  \n4     31.0  83330.0  421004.0  121570.0   483682.0  \n5  95112.0  28590.0  791573.0   15960.0   250289.0  \n6      0.0    120.0      94.0    1290.0     2792.0  \n7      0.0    210.0     301.0    1130.0     2935.0  \n\n[8 rows x 131 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATEFIPS</th>\n      <th>STATE</th>\n      <th>zipcode</th>\n      <th>agi_stub</th>\n      <th>N1</th>\n      <th>mars1</th>\n      <th>MARS2</th>\n      <th>MARS4</th>\n      <th>PREP</th>\n      <th>N2</th>\n      <th>...</th>\n      <th>N10300</th>\n      <th>A10300</th>\n      <th>N85530</th>\n      <th>A85530</th>\n      <th>N85300</th>\n      <th>A85300</th>\n      <th>N11901</th>\n      <th>A11901</th>\n      <th>N11902</th>\n      <th>A11902</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>AL</td>\n      <td>0</td>\n      <td>1</td>\n      <td>836320.0</td>\n      <td>481570.0</td>\n      <td>109790.0</td>\n      <td>233260.0</td>\n      <td>455560.0</td>\n      <td>1356760.0</td>\n      <td>...</td>\n      <td>373410.0</td>\n      <td>328469.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>61920.0</td>\n      <td>48150.0</td>\n      <td>732670.0</td>\n      <td>1933120.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>AL</td>\n      <td>0</td>\n      <td>2</td>\n      <td>494830.0</td>\n      <td>206630.0</td>\n      <td>146250.0</td>\n      <td>129390.0</td>\n      <td>275920.0</td>\n      <td>1010990.0</td>\n      <td>...</td>\n      <td>395880.0</td>\n      <td>965011.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>73720.0</td>\n      <td>107304.0</td>\n      <td>415410.0</td>\n      <td>1187403.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>AL</td>\n      <td>0</td>\n      <td>3</td>\n      <td>261250.0</td>\n      <td>80720.0</td>\n      <td>139280.0</td>\n      <td>36130.0</td>\n      <td>155100.0</td>\n      <td>583910.0</td>\n      <td>...</td>\n      <td>251490.0</td>\n      <td>1333418.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>64200.0</td>\n      <td>139598.0</td>\n      <td>193030.0</td>\n      <td>536699.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>AL</td>\n      <td>0</td>\n      <td>4</td>\n      <td>166690.0</td>\n      <td>28510.0</td>\n      <td>124650.0</td>\n      <td>10630.0</td>\n      <td>99950.0</td>\n      <td>423990.0</td>\n      <td>...</td>\n      <td>165320.0</td>\n      <td>1414283.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>45460.0</td>\n      <td>128823.0</td>\n      <td>116440.0</td>\n      <td>377177.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>AL</td>\n      <td>0</td>\n      <td>5</td>\n      <td>212660.0</td>\n      <td>19520.0</td>\n      <td>184320.0</td>\n      <td>4830.0</td>\n      <td>126860.0</td>\n      <td>589490.0</td>\n      <td>...</td>\n      <td>212000.0</td>\n      <td>3820152.0</td>\n      <td>420.0</td>\n      <td>168.0</td>\n      <td>60.0</td>\n      <td>31.0</td>\n      <td>83330.0</td>\n      <td>421004.0</td>\n      <td>121570.0</td>\n      <td>483682.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>AL</td>\n      <td>0</td>\n      <td>6</td>\n      <td>55360.0</td>\n      <td>2950.0</td>\n      <td>49260.0</td>\n      <td>350.0</td>\n      <td>41410.0</td>\n      <td>160530.0</td>\n      <td>...</td>\n      <td>55300.0</td>\n      <td>6027793.0</td>\n      <td>22090.0</td>\n      <td>39519.0</td>\n      <td>27550.0</td>\n      <td>95112.0</td>\n      <td>28590.0</td>\n      <td>791573.0</td>\n      <td>15960.0</td>\n      <td>250289.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>AL</td>\n      <td>35004</td>\n      <td>1</td>\n      <td>1490.0</td>\n      <td>970.0</td>\n      <td>230.0</td>\n      <td>280.0</td>\n      <td>700.0</td>\n      <td>2160.0</td>\n      <td>...</td>\n      <td>690.0</td>\n      <td>610.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>94.0</td>\n      <td>1290.0</td>\n      <td>2792.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>AL</td>\n      <td>35004</td>\n      <td>2</td>\n      <td>1350.0</td>\n      <td>630.0</td>\n      <td>360.0</td>\n      <td>300.0</td>\n      <td>610.0</td>\n      <td>2540.0</td>\n      <td>...</td>\n      <td>1140.0</td>\n      <td>3019.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>210.0</td>\n      <td>301.0</td>\n      <td>1130.0</td>\n      <td>2935.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 131 columns</p>\n</div>"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "tax_data.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Modify `tax_data` to uppercase all the header names. \n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "  * Do not hardcode the operation by uppercasing the columns yourself\n",
    "  *  You can use `tax_data.columns`, which returns a `Series` of the column names.\n",
    "\n",
    "* The resulting column name should look as follows:\n",
    "\n",
    "```\n",
    "STATEFIPS    STATE    ZIPCODE    AGI_STUB    N1    MARS1    MARS2    MARS4    PREP    N2    ...    \n",
    "```\n",
    "\n",
    "* Standardizing column names is a good way to avoid having to guess whether the column header is in lowercase or uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATEFIPS', 'STATE', 'ZIPCODE', 'AGI_STUB', 'N1', 'MARS1', 'MARS2',\n",
      "       'MARS4', 'PREP', 'N2',\n",
      "       ...\n",
      "       'N10300', 'A10300', 'N85530', 'A85530', 'N85300', 'A85300', 'N11901',\n",
      "       'A11901', 'N11902', 'A11902'],\n",
      "      dtype='object', length=131)\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "tax_data = tax_data.rename(columns=lambda x: x.upper())\n",
    "print(tax_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the total number of entries (also called observations or instances) in `tax_data` dataset?\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21837438\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "print(tax_data.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If `STATEFIPS` is the header label of the first column in `tax_data`, write code to print the title of the 32nd column.  \n",
    "  * You should use a single python expression\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A00900\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "print(tax_data.columns[32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If `STATEFIPS` is the first column label (index 0), what is the index of the column labeled `N10300`?\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "print(tax_data.columns.get_loc(\"N10300\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the count of unique zip codes in each state using descending order.\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "\n",
    "- The result should look like the following ( '...' represents remaining data that is not shown here)\n",
    "```python\n",
    "\n",
    "        ZIPCODE\n",
    "STATE\t\n",
    "TX\t     9714\n",
    "NY\t     9238\n",
    "CA\t     8908\n",
    "PA\t     8208\n",
    "IL\t     7386\n",
    "...\n",
    "```\n",
    "\n",
    "* The above indicates that there are 9,714 unique zip codes in TX, 9,238 in NY, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE\n",
      "TX    1619\n",
      "NY    1540\n",
      "CA    1485\n",
      "PA    1368\n",
      "IL    1231\n",
      "OH     998\n",
      "FL     920\n",
      "MI     892\n",
      "MO     890\n",
      "IA     827\n",
      "VA     793\n",
      "MN     792\n",
      "NC     725\n",
      "WI     714\n",
      "IN     674\n",
      "GA     667\n",
      "KY     656\n",
      "KS     598\n",
      "TN     590\n",
      "AL     577\n",
      "OK     547\n",
      "NJ     547\n",
      "WV     512\n",
      "WA     497\n",
      "AR     490\n",
      "NE     486\n",
      "MA     482\n",
      "LA     453\n",
      "MD     405\n",
      "CO     395\n",
      "SC     376\n",
      "ME     370\n",
      "MS     370\n",
      "OR     356\n",
      "AZ     295\n",
      "ND     287\n",
      "SD     287\n",
      "CT     264\n",
      "VT     238\n",
      "NH     232\n",
      "MT     225\n",
      "ID     213\n",
      "NM     209\n",
      "UT     186\n",
      "NV     128\n",
      "WY     109\n",
      "RI      71\n",
      "HI      60\n",
      "DE      57\n",
      "AK      56\n",
      "DC      24\n",
      "Name: ZIPCODE, dtype: int64\n",
      "   STATE  ZIPCODE\n",
      "0     AK       56\n",
      "1     AL      577\n",
      "2     AR      490\n",
      "3     AZ      295\n",
      "4     CA     1485\n",
      "5     CO      395\n",
      "6     CT      264\n",
      "7     DC       24\n",
      "8     DE       57\n",
      "9     FL      920\n",
      "10    GA      667\n",
      "11    HI       60\n",
      "12    IA      827\n",
      "13    ID      213\n",
      "14    IL     1231\n",
      "15    IN      674\n",
      "16    KS      598\n",
      "17    KY      656\n",
      "18    LA      453\n",
      "19    MA      482\n",
      "20    MD      405\n",
      "21    ME      370\n",
      "22    MI      892\n",
      "23    MN      792\n",
      "24    MO      890\n",
      "25    MS      370\n",
      "26    MT      225\n",
      "27    NC      725\n",
      "28    ND      287\n",
      "29    NE      486\n",
      "30    NH      232\n",
      "31    NJ      547\n",
      "32    NM      209\n",
      "33    NV      128\n",
      "34    NY     1540\n",
      "35    OH      998\n",
      "36    OK      547\n",
      "37    OR      356\n",
      "38    PA     1368\n",
      "39    RI       71\n",
      "40    SC      376\n",
      "41    SD      287\n",
      "42    TN      590\n",
      "43    TX     1619\n",
      "44    UT      186\n",
      "45    VA      793\n",
      "46    VT      238\n",
      "47    WA      497\n",
      "48    WI      714\n",
      "49    WV      512\n",
      "50    WY      109\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "#Get Series of States\n",
    "unique_zipByState = tax_data.groupby(\"STATE\")[\"ZIPCODE\"].nunique()\n",
    "print(unique_zipByState.sort_values(ascending=False))\n",
    "unique_zipByState = unique_zipByState.to_frame().reset_index()\n",
    "print(unique_zipByState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Identify the position of `HI` in the list of zip code counts per state generated in the previous question\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI position:  11\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "print(\"HI position: \", unique_zipByState['STATE'].loc[lambda x: x==\"HI\"].index.values[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identifying and Removing Ambiguous Zip Codes\n",
    "\n",
    "- Count the number of entries where ZIPCODE is 0, assign your results to a variable named  `nb_invalid_zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "nb_invalid_zip = int(tax_data.loc[tax_data.ZIPCODE == 0, 'ZIPCODE'].count())\n",
    "print(nb_invalid_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line in the code cell below to make sure that `nb_invalid_zip` is an integer (`int`)\n",
    "  * Note that `assert` will only print an error if `type(nb_invalid_zip)` is not of type `int`\n",
    "* If the code cell below returns an error, then change your answer above so that the value returned is a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(type(nb_invalid_zip) == int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove from `tax_data` all the instances where the zip code is `0` and save the resulting `DataFrame` to a variable named `tax_data_valid_zip`\n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    STATEFIPS STATE  ZIPCODE  AGI_STUB      N1  MARS1  MARS2  MARS4   PREP  \\\n",
      "6           1    AL    35004         1  1490.0  970.0  230.0  280.0  700.0   \n",
      "7           1    AL    35004         2  1350.0  630.0  360.0  300.0  610.0   \n",
      "8           1    AL    35004         3   970.0  310.0  490.0  140.0  450.0   \n",
      "9           1    AL    35004         4   620.0  110.0  470.0   30.0  300.0   \n",
      "10          1    AL    35004         5   620.0   40.0  560.0   20.0  320.0   \n",
      "\n",
      "        N2  ...  N10300   A10300  N85530  A85530  N85300  A85300  N11901  \\\n",
      "6   2160.0  ...   690.0    610.0     0.0     0.0     0.0     0.0   120.0   \n",
      "7   2540.0  ...  1140.0   3019.0     0.0     0.0     0.0     0.0   210.0   \n",
      "8   2160.0  ...   930.0   5009.0     0.0     0.0     0.0     0.0   200.0   \n",
      "9   1610.0  ...   620.0   5190.0     0.0     0.0     0.0     0.0   150.0   \n",
      "10  1770.0  ...   620.0  10129.0     0.0     0.0     0.0     0.0   220.0   \n",
      "\n",
      "    A11901  N11902  A11902  \n",
      "6     94.0  1290.0  2792.0  \n",
      "7    301.0  1130.0  2935.0  \n",
      "8    376.0   760.0  2058.0  \n",
      "9    374.0   460.0  1390.0  \n",
      "10   854.0   410.0  1709.0  \n",
      "\n",
      "[5 rows x 131 columns]\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "tax_data_valid_zip = tax_data[tax_data.ZIPCODE != 0]\n",
    "print(tax_data_valid_zip.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line below to confirm that the operation worked as expected\n",
    "\n",
    "  * The assertion below verifies that the number of lines with \"zip code equal to  0\" + number of lines in `tax_data_valid_zip` is equal to the number of lines in the original `DataFrame` `tax_data`\n",
    "  \n",
    "  * The assertion below will fail (and print an error message) if the results do not match. If that is the case, please review your code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert((tax_data_valid_zip.shape[0] + nb_invalid_zip) == tax_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying and Removing Lines with Missing Values\n",
    "\n",
    "* How many lines contain at least one missing value `NaN` in the `tax_data_valid_zip` `DataFrame`?\n",
    "  * Your answer can only use `DataFrame` methods and properties\n",
    "* Assing the count of `NaN` into a variable called nb_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n",
    "#Row Count that contains NaN\n",
    "print(len(tax_data_valid_zip) - len(tax_data_valid_zip.dropna()))\n",
    "\n",
    "#All NaN Count\n",
    "nb_missing_values = tax_data_valid_zip.isna().sum().sum()\n",
    "print(nb_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a new `DataFrame` containing all the lines from `tax_data_valid_zip`, except lines containing missing values (`NaN`)\n",
    "\n",
    "* Call the new `DataFrame` `tax_data_valid_zip_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        STATEFIPS STATE  ZIPCODE  AGI_STUB      N1   MARS1   MARS2   MARS4  \\\n",
      "6               1    AL    35004         1  1490.0   970.0   230.0   280.0   \n",
      "7               1    AL    35004         2  1350.0   630.0   360.0   300.0   \n",
      "8               1    AL    35004         3   970.0   310.0   490.0   140.0   \n",
      "9               1    AL    35004         4   620.0   110.0   470.0    30.0   \n",
      "10              1    AL    35004         5   620.0    40.0   560.0    20.0   \n",
      "11              1    AL    35004         6    60.0     0.0    50.0     0.0   \n",
      "12              1    AL    35005         1  1350.0   750.0   190.0   390.0   \n",
      "13              1    AL    35005         2   980.0   370.0   230.0   350.0   \n",
      "14              1    AL    35005         3   490.0   150.0   210.0   120.0   \n",
      "15              1    AL    35005         4   250.0    50.0   180.0    40.0   \n",
      "16              1    AL    35005         5   190.0     0.0   160.0     0.0   \n",
      "17              1    AL    35005         6     0.0     0.0     0.0     0.0   \n",
      "18              1    AL    35006         1   430.0   260.0   100.0    70.0   \n",
      "19              1    AL    35006         2   340.0   120.0   150.0    70.0   \n",
      "20              1    AL    35006         3   190.0    30.0   130.0    30.0   \n",
      "21              1    AL    35006         4   130.0    30.0   100.0     0.0   \n",
      "22              1    AL    35006         5   140.0     0.0   130.0     0.0   \n",
      "23              1    AL    35006         6     0.0     0.0     0.0     0.0   \n",
      "24              1    AL    35007         1  4170.0  2750.0   560.0   780.0   \n",
      "25              1    AL    35007         2  2700.0  1160.0   840.0   590.0   \n",
      "26              1    AL    35007         3  1840.0   570.0   950.0   260.0   \n",
      "27              1    AL    35007         4  1440.0   190.0  1140.0    80.0   \n",
      "28              1    AL    35007         5  1780.0   130.0  1590.0    70.0   \n",
      "29              1    AL    35007         6   240.0     0.0   220.0     0.0   \n",
      "30              1    AL    35010         1  3830.0  1920.0   500.0  1350.0   \n",
      "31              1    AL    35010         2  2170.0   750.0   630.0   730.0   \n",
      "32              1    AL    35010         3   890.0   230.0   530.0   130.0   \n",
      "33              1    AL    35010         4   540.0    60.0   460.0     0.0   \n",
      "34              1    AL    35010         5   550.0    40.0   500.0    20.0   \n",
      "35              1    AL    35010         6   180.0     0.0   170.0     0.0   \n",
      "...           ...   ...      ...       ...     ...     ...     ...     ...   \n",
      "166668         56    WY    83126         1    60.0    60.0    40.0     0.0   \n",
      "166669         56    WY    83126         2    30.0     0.0     0.0     0.0   \n",
      "166670         56    WY    83126         3    40.0     0.0    30.0     0.0   \n",
      "166671         56    WY    83126         4    40.0     0.0    40.0     0.0   \n",
      "166672         56    WY    83126         5     0.0     0.0     0.0     0.0   \n",
      "166673         56    WY    83126         6     0.0     0.0     0.0     0.0   \n",
      "166674         56    WY    83127         1   380.0   240.0    80.0    50.0   \n",
      "166675         56    WY    83127         2   300.0   120.0   150.0    40.0   \n",
      "166676         56    WY    83127         3   230.0    70.0   150.0     0.0   \n",
      "166677         56    WY    83127         4   190.0    30.0   160.0     0.0   \n",
      "166678         56    WY    83127         5   230.0    20.0   200.0     0.0   \n",
      "166679         56    WY    83127         6    70.0     0.0    60.0     0.0   \n",
      "166680         56    WY    83128         1   250.0   190.0    30.0    30.0   \n",
      "166681         56    WY    83128         2   210.0   120.0    60.0    30.0   \n",
      "166682         56    WY    83128         3   160.0    70.0    90.0     0.0   \n",
      "166683         56    WY    83128         4    90.0     0.0    80.0     0.0   \n",
      "166684         56    WY    83128         5   100.0    30.0    90.0     0.0   \n",
      "166685         56    WY    83128         6    50.0     0.0    40.0     0.0   \n",
      "166686         56    WY    83414         1    60.0    50.0     0.0     0.0   \n",
      "166687         56    WY    83414         2    60.0    40.0    50.0     0.0   \n",
      "166688         56    WY    83414         3     0.0     0.0     0.0     0.0   \n",
      "166689         56    WY    83414         4    20.0     0.0     0.0     0.0   \n",
      "166690         56    WY    83414         5    30.0     0.0    30.0     0.0   \n",
      "166691         56    WY    83414         6    30.0     0.0    30.0     0.0   \n",
      "166692         56    WY    99999         1  5360.0  3990.0   710.0   610.0   \n",
      "166693         56    WY    99999         2  3680.0  2000.0  1080.0   490.0   \n",
      "166694         56    WY    99999         3  2630.0  1100.0  1240.0   250.0   \n",
      "166695         56    WY    99999         4  2020.0   590.0  1310.0   100.0   \n",
      "166696         56    WY    99999         5  2670.0   430.0  2170.0    90.0   \n",
      "166697         56    WY    99999         6   760.0   140.0   650.0     0.0   \n",
      "\n",
      "          PREP      N2  ...  N10300    A10300  N85530  A85530  N85300  A85300  \\\n",
      "6        700.0  2160.0  ...   690.0     610.0     0.0     0.0     0.0     0.0   \n",
      "7        610.0  2540.0  ...  1140.0    3019.0     0.0     0.0     0.0     0.0   \n",
      "8        450.0  2160.0  ...   930.0    5009.0     0.0     0.0     0.0     0.0   \n",
      "9        300.0  1610.0  ...   620.0    5190.0     0.0     0.0     0.0     0.0   \n",
      "10       320.0  1770.0  ...   620.0   10129.0     0.0     0.0     0.0     0.0   \n",
      "11        50.0   150.0  ...    60.0    3680.0     0.0     0.0    20.0    30.0   \n",
      "12       730.0  2300.0  ...   610.0     545.0     0.0     0.0     0.0     0.0   \n",
      "13       530.0  1970.0  ...   770.0    1679.0     0.0     0.0     0.0     0.0   \n",
      "14       290.0  1070.0  ...   460.0    2373.0     0.0     0.0     0.0     0.0   \n",
      "15       150.0   620.0  ...   250.0    2098.0     0.0     0.0     0.0     0.0   \n",
      "16       110.0   490.0  ...   190.0    3802.0     0.0     0.0     0.0     0.0   \n",
      "17         0.0     0.0  ...     0.0       0.0     0.0     0.0     0.0     0.0   \n",
      "18       240.0   680.0  ...   220.0     207.0     0.0     0.0     0.0     0.0   \n",
      "19       230.0   720.0  ...   280.0     626.0     0.0     0.0     0.0     0.0   \n",
      "20       120.0   490.0  ...   180.0     850.0     0.0     0.0     0.0     0.0   \n",
      "21       100.0   330.0  ...   130.0    1060.0     0.0     0.0     0.0     0.0   \n",
      "22       100.0   420.0  ...   140.0    2547.0     0.0     0.0     0.0     0.0   \n",
      "23         0.0     0.0  ...     0.0       0.0     0.0     0.0     0.0     0.0   \n",
      "24      1690.0  5820.0  ...  2070.0    1978.0     0.0     0.0     0.0     0.0   \n",
      "25      1190.0  5620.0  ...  2240.0    5667.0     0.0     0.0     0.0     0.0   \n",
      "26       880.0  4310.0  ...  1770.0    9372.0     0.0     0.0     0.0     0.0   \n",
      "27       660.0  3980.0  ...  1420.0   11664.0     0.0     0.0     0.0     0.0   \n",
      "28       850.0  5290.0  ...  1780.0   29869.0     0.0     0.0     0.0     0.0   \n",
      "29       160.0   740.0  ...   240.0   15369.0    70.0    63.0    90.0   119.0   \n",
      "30      1760.0  6610.0  ...  1520.0    1221.0     0.0     0.0     0.0     0.0   \n",
      "31      1130.0  4930.0  ...  1630.0    3646.0     0.0     0.0     0.0     0.0   \n",
      "32       530.0  2060.0  ...   860.0    4434.0     0.0     0.0     0.0     0.0   \n",
      "33       340.0  1430.0  ...   530.0    4263.0     0.0     0.0     0.0     0.0   \n",
      "34       380.0  1520.0  ...   550.0    9115.0     0.0     0.0     0.0     0.0   \n",
      "35       150.0   470.0  ...   180.0   15130.0    70.0    76.0    90.0   357.0   \n",
      "...        ...     ...  ...     ...       ...     ...     ...     ...     ...   \n",
      "166668    50.0    60.0  ...    30.0      13.0     0.0     0.0     0.0     0.0   \n",
      "166669     0.0    70.0  ...    30.0      75.0     0.0     0.0     0.0     0.0   \n",
      "166670    20.0   130.0  ...    30.0     154.0     0.0     0.0     0.0     0.0   \n",
      "166671    30.0   160.0  ...    40.0     490.0     0.0     0.0     0.0     0.0   \n",
      "166672     0.0     0.0  ...     0.0       0.0     0.0     0.0     0.0     0.0   \n",
      "166673     0.0     0.0  ...     0.0       0.0     0.0     0.0     0.0     0.0   \n",
      "166674   170.0   500.0  ...   170.0     151.0     0.0     0.0     0.0     0.0   \n",
      "166675   130.0   620.0  ...   260.0     711.0     0.0     0.0     0.0     0.0   \n",
      "166676   130.0   550.0  ...   220.0    1149.0     0.0     0.0     0.0     0.0   \n",
      "166677   110.0   520.0  ...   190.0    1466.0     0.0     0.0     0.0     0.0   \n",
      "166678   130.0   570.0  ...   220.0    3796.0     0.0     0.0     0.0     0.0   \n",
      "166679    60.0   170.0  ...    70.0    5936.0     0.0     0.0    40.0   109.0   \n",
      "166680   100.0   290.0  ...   140.0     141.0     0.0     0.0     0.0     0.0   \n",
      "166681   100.0   360.0  ...   200.0     654.0     0.0     0.0     0.0     0.0   \n",
      "166682    80.0   360.0  ...   160.0     893.0     0.0     0.0     0.0     0.0   \n",
      "166683    60.0   230.0  ...    90.0     792.0     0.0     0.0     0.0     0.0   \n",
      "166684    60.0   240.0  ...   100.0    1841.0     0.0     0.0     0.0     0.0   \n",
      "166685    50.0   110.0  ...    50.0    8774.0     0.0     0.0    30.0   201.0   \n",
      "166686    40.0    50.0  ...    30.0      27.0     0.0     0.0     0.0     0.0   \n",
      "166687    60.0   150.0  ...    50.0     205.0     0.0     0.0     0.0     0.0   \n",
      "166688     0.0     0.0  ...     0.0       0.0     0.0     0.0     0.0     0.0   \n",
      "166689     0.0    50.0  ...    20.0     184.0     0.0     0.0     0.0     0.0   \n",
      "166690    30.0    90.0  ...    30.0     466.0     0.0     0.0     0.0     0.0   \n",
      "166691    20.0    70.0  ...    30.0    5821.0     0.0     0.0    20.0   169.0   \n",
      "166692  2540.0  6860.0  ...  2730.0    2388.0     0.0     0.0     0.0     0.0   \n",
      "166693  2020.0  6660.0  ...  3220.0    9235.0     0.0     0.0     0.0     0.0   \n",
      "166694  1610.0  5440.0  ...  2530.0   15579.0     0.0     0.0     0.0     0.0   \n",
      "166695  1330.0  4780.0  ...  1990.0   19278.0     0.0     0.0     0.0     0.0   \n",
      "166696  1850.0  6930.0  ...  2650.0   49853.0     0.0     0.0     0.0     0.0   \n",
      "166697   720.0  1890.0  ...   760.0  139792.0   170.0   198.0   490.0  3842.0   \n",
      "\n",
      "        N11901   A11901  N11902   A11902  \n",
      "6        120.0     94.0  1290.0   2792.0  \n",
      "7        210.0    301.0  1130.0   2935.0  \n",
      "8        200.0    376.0   760.0   2058.0  \n",
      "9        150.0    374.0   460.0   1390.0  \n",
      "10       220.0    854.0   410.0   1709.0  \n",
      "11        30.0    357.0     0.0      0.0  \n",
      "12       100.0     74.0  1200.0   3243.0  \n",
      "13       100.0    116.0   880.0   2501.0  \n",
      "14       100.0    226.0   390.0   1136.0  \n",
      "15        50.0    133.0   200.0    650.0  \n",
      "16        80.0    485.0   100.0    373.0  \n",
      "17         0.0      0.0     0.0      0.0  \n",
      "18        30.0     16.0   380.0    835.0  \n",
      "19        40.0     45.0   290.0    846.0  \n",
      "20        30.0     64.0   160.0    525.0  \n",
      "21        30.0     65.0   100.0    357.0  \n",
      "22        50.0    204.0    90.0    342.0  \n",
      "23         0.0      0.0     0.0      0.0  \n",
      "24       480.0    374.0  3430.0   6736.0  \n",
      "25       460.0    667.0  2210.0   5858.0  \n",
      "26       450.0   1038.0  1380.0   3738.0  \n",
      "27       400.0   1040.0  1020.0   3216.0  \n",
      "28       720.0   2839.0  1020.0   3571.0  \n",
      "29       140.0   3185.0    80.0    518.0  \n",
      "30       230.0    158.0  3420.0   9913.0  \n",
      "31       260.0    339.0  1890.0   5984.0  \n",
      "32       220.0    461.0   650.0   1788.0  \n",
      "33       140.0    286.0   370.0   1147.0  \n",
      "34       250.0   1030.0   270.0   1096.0  \n",
      "35       100.0   1815.0    60.0    531.0  \n",
      "...        ...      ...     ...      ...  \n",
      "166668     0.0      0.0    70.0    115.0  \n",
      "166669     0.0      0.0     0.0      0.0  \n",
      "166670    30.0     41.0    20.0    104.0  \n",
      "166671     0.0      0.0    20.0     57.0  \n",
      "166672     0.0      0.0     0.0      0.0  \n",
      "166673     0.0      0.0     0.0      0.0  \n",
      "166674    50.0     38.0   260.0    489.0  \n",
      "166675    60.0    123.0   230.0    581.0  \n",
      "166676    80.0    146.0   150.0    405.0  \n",
      "166677    70.0    207.0   110.0    339.0  \n",
      "166678   110.0    660.0   120.0    529.0  \n",
      "166679    40.0   1500.0     0.0      0.0  \n",
      "166680    30.0     31.0   200.0    292.0  \n",
      "166681    50.0    117.0   160.0    366.0  \n",
      "166682    50.0    144.0   100.0    224.0  \n",
      "166683    30.0     92.0    60.0    179.0  \n",
      "166684    70.0   1321.0    50.0    223.0  \n",
      "166685     0.0      0.0     0.0      0.0  \n",
      "166686    20.0     36.0    40.0     51.0  \n",
      "166687     0.0      0.0    60.0    221.0  \n",
      "166688     0.0      0.0     0.0      0.0  \n",
      "166689     0.0      0.0     0.0      0.0  \n",
      "166690    20.0    430.0    30.0    546.0  \n",
      "166691     0.0      0.0     0.0      0.0  \n",
      "166692   440.0    311.0  4330.0   7361.0  \n",
      "166693   550.0    869.0  2960.0   7717.0  \n",
      "166694   560.0   1273.0  1890.0   5330.0  \n",
      "166695   470.0   1635.0  1390.0   4696.0  \n",
      "166696   950.0   5576.0  1460.0   6853.0  \n",
      "166697   340.0  14487.0   160.0  21167.0  \n",
      "\n",
      "[166392 rows x 131 columns]\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "tax_data_valid_zip_cleaned = tax_data_valid_zip.dropna()\n",
    "print(tax_data_valid_zip_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line below to confirm that the operation worked as expected. The assertion below tests that:  \n",
    "`nb_missing_values` + number of lines in `tax_data_valid_zip_cleaned` is equal to the number of lines in `tax_data_valid_zip`\n",
    "  \n",
    "* Note that assert will only print an error if the results do not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert((tax_data_valid_zip_cleaned.shape[0] + nb_missing_values) == tax_data_valid_zip.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Percentile Income per Zip Code\n",
    "* The function `compute_percentile_zipcode` below computes the percentile income per zip code\n",
    "* By default `percentile=0.5`, i.e., the function computes the median\n",
    "* Read the code and make sure you understand what it does before moving on to the next question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_percentile_zip(df_zip, percentile=0.5):     \n",
    "    index_median = sum(( df_zip[\"N1\"]/ sum(df_zip[\"N1\"])).cumsum() <= percentile)\n",
    "    val_below_or_at_median = (df_zip[\"A00100\"] /df_zip[\"N1\"]).iloc[index_median]\n",
    "    return val_below_or_at_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the 65th income percentile ( percentile=0.65) for each zip code in `tax_data_valid_zip_cleaned` data frame\n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "  \n",
    "  * You can use any of the submethods discussed in the Split-Apply-Combine paradigm.\n",
    "  \n",
    "* Sort the values in descending order and assign them to a new `DataFrame` called `zip_rev_all`\n",
    "\n",
    "* The resulting `Series` should look like the following ( '...' represents remaining data that is not shown)\n",
    "\n",
    "```Python\n",
    "ZIPCODE\n",
    "33109    3954.114286\n",
    "33480    3413.301538\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.647147147147145\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('N1', 'occurred at index STATEFIPS')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-145-5ba5a3cd152c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m#computed row\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mtax_data_valid_zip_cleaned\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'computed_test'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtax_data_valid_zip_cleaned\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mrow\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mcompute_percentile_zip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpercentile\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.65\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;31m#computation test\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001B[0m\n\u001B[1;32m   6485\u001B[0m                          \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6486\u001B[0m                          kwds=kwds)\n\u001B[0;32m-> 6487\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6488\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6489\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapplymap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mget_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    149\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_raw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 151\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    152\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_empty_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    256\u001B[0m         \u001B[0;31m# compute the result using the series generator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 257\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_series_generator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    258\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    259\u001B[0m         \u001B[0;31m# wrap results\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    285\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseries_gen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 286\u001B[0;31m                     \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    287\u001B[0m                     \u001B[0mkeys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    288\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-145-5ba5a3cd152c>\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(row)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m#computed row\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mtax_data_valid_zip_cleaned\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'computed_test'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtax_data_valid_zip_cleaned\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mrow\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mcompute_percentile_zip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpercentile\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.65\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;31m#computation test\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-144-b8d74b6be5fa>\u001B[0m in \u001B[0;36mcompute_percentile_zip\u001B[0;34m(df_zip, percentile)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mcompute_percentile_zip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_zip\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpercentile\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mindex_median\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mdf_zip\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"N1\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m/\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_zip\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"N1\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcumsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mpercentile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mval_below_or_at_median\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdf_zip\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"A00100\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m/\u001B[0m\u001B[0mdf_zip\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"N1\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex_median\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mval_below_or_at_median\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    866\u001B[0m         \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_if_callable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    867\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 868\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    869\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    870\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_value\u001B[0;34m(self, series, key)\u001B[0m\n\u001B[1;32m   4373\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4374\u001B[0m             return self._engine.get_value(s, k,\n\u001B[0;32m-> 4375\u001B[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001B[0m\u001B[1;32m   4376\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4377\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mholds_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_boolean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_value\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_value\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.index.Int64Engine._check_type\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: ('N1', 'occurred at index STATEFIPS')"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "#print(tax_data_valid_zip_cleaned.head(5))\n",
    "print(compute_percentile_zip(tax_data_valid_zip_cleaned, percentile=0.65))\n",
    "\n",
    "#computed row\n",
    "tax_data_valid_zip_cleaned['computed_test'] = tax_data_valid_zip_cleaned.apply(lambda row : (compute_percentile_zip(row, percentile=0.65)))\n",
    "\n",
    "#computation test\n",
    "print(tax_data_valid_zip_cleaned['computed_test'])\n",
    "\n",
    "#sorted order Series\n",
    "zip_rev_all = tax_data_valid_zip_cleaned.sorted_order(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What are the three zip codes with the most significant 65th percentile value for income?\n",
    " * I.e., the top three zip codes in your sorted listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zip_rev_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-146-447aa8a1d108>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m## WRITE YOUR CODE HERE\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip_rev_all\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'ZIPCODE'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'zip_rev_all' is not defined"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "print(zip_rev_all['ZIPCODE'].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Working with the Medicaid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and exploring the data \n",
    "\n",
    "* Load the Medicaid data stored in the file `medicaid_data.csv` into a `DataFrame` called `medicaid_data`. The file can be downloaded from the URL provided above. \n",
    "* Note that this is quite large and may take some time to load on a computer with modest RAM resources (e.g., less than 6-8 GB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "medicaid_data = pd.read_csv('medicaid_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify `medicaid_data` to capitalize all column names \n",
    "\n",
    "  * If your solution uses an assignment, the righthand side of the assignment (rvalue) can only use `DataFrame` or `Series` methods or properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "medicaid_data = medicaid_data.rename(columns=lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Familiarize yourself with the data\n",
    "  * the `NDC` column stands for National Drug Code, a universal product identifier for human drugs in the United States\n",
    "  * The remaining column names are self-explanatory\n",
    "* Explore the number of lines and columns in the data\n",
    "* Check that your column headers are capitalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 16955460\n",
      "Shape: (1695546, 10)\n",
      "Index(['UTILIZATION TYPE', 'STATE', 'NDC', 'PRODUCT NAME', 'UNITS REIMBURSED',\n",
      "       'NUMBER OF PRESCRIPTIONS', 'TOTAL AMOUNT REIMBURSED',\n",
      "       'MEDICAID AMOUNT REIMBURSED', 'NON MEDICAID AMOUNT REIMBURSED',\n",
      "       'LOCATION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "print(\"Size:\", medicaid_data.size)\n",
    "print(\"Shape:\", medicaid_data.shape)\n",
    "print(medicaid_data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you explore the `LOCATION` column for all the entries for which \"STATE\" value is equal to \"HI\" you'll notice that all the values are identical.\n",
    "* Are there any states that have more than one value for `LOCATION`. \n",
    "  * This question can be answered by using aggregation and the Split-Apply-Combine paradigm\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154    (21.1098, -157.5311)\n",
      "294    (21.1098, -157.5311)\n",
      "318    (21.1098, -157.5311)\n",
      "397    (21.1098, -157.5311)\n",
      "557    (21.1098, -157.5311)\n",
      "Name: LOCATION, dtype: object\n",
      "  STATE              LOCATION  count\n",
      "0    AK   (61.385, -152.2683)  12265\n",
      "1    AL    (32.799, -86.8073)  23547\n",
      "2    AR   (34.9513, -92.3809)  18276\n",
      "3    AZ  (33.7712, -111.3877)  27348\n",
      "4    CA    (36.17, -119.7462)  76996\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "#HI Location Phenomena - LOCATION values are all same\n",
    "db = medicaid_data[medicaid_data[\"STATE\"] == \"HI\"]\n",
    "print(db[\"LOCATION\"].head(5))\n",
    "\n",
    "#Checking for the same phenomena for other states\n",
    "count_LOCATION = medicaid_data.groupby(['STATE', 'LOCATION']).size().reset_index(name='count')\n",
    "print(count_LOCATION.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Yes. Based by the aggregation analysis, there are states that have identical LOCATION values as indicated by the 'count' column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To compare medication prescriptions across states in a fair and balanced way, we need the number of Medicaid beneficiaries in each state.  That is, we need to compare per capita. The following example illustrates the importance of normalizing the values `UNITS REIMBURSED` for each medication in each state by the number of Medicaid enrollees in each state.\n",
    "\n",
    " \n",
    "* The `medicaid_data` DataFrame shows that for the drug with NDC `61958180101` (the drug name is HARVONI and it's used to treat Hepatitis C) there were 11,886  units sold in KY, versus 40,142 in CA -- that's almost 4 times more units sold in CA compared to KY. However, there are 1,284,193 Medicaid enrollees in KY, versus 13,096,861 in California. If we normalize the number of units sold in KY, versus CA, we find that the normalized there were close to 3 times more HARVONI prescriptions in KY  than in CA. This is ___perhaps___ justified by the fact the KY has one of the highest rates of reported cases of Hepatitis C in the US (2.7% in KY versus 0.2% in CA).\n",
    "\n",
    "\n",
    "https://www.cdc.gov/hepatitis/statistics/2015surveillance/pdfs/2015hepsurveillancerpt.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of enrollees per state was obtained [here](https://www.medicaid.gov/medicaid/managed-care/enrollment/index.html)\n",
    "\n",
    "* A parsed/processed version (`medicaid_enrollment.tsv`) can be downloaded from the URL provided above. Use `pandas` to load the `medicaid_enrollment.tsv` file into DataFrame named `medicaid_enrollment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "medicaid_enrollment= pd.read_csv(\"medicaid_enrollment.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify `medicaid_enrollment` `DataFrame` to capitalize all the column names \n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "  * Do not hardcode the operation by manually uppercasing the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATE', 'TOTAL MEDICAID ENROLLEES'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "medicaid_enrollment = medicaid_enrollment.rename(columns=lambda x: x.upper())\n",
    "print(medicaid_enrollment.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that some states/territories have missing values. Remove the missing values and save the resulting `DataFrame` as a new variable named `medicaid_enrollment_cleaned`\n",
    "* Pay attention to how 'n/a' is given here!\n",
    "* After cleaning, do you still have the Guam entry? If so, reconsider what missing value means in this context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   STATE TOTAL MEDICAID ENROLLEES\n",
      "12  Guam                      n/a\n",
      "                   STATE TOTAL MEDICAID ENROLLEES\n",
      "0                Alabama                1,050,989\n",
      "1                 Alaska                  164,783\n",
      "3                Arizona                1,740,520\n",
      "4               Arkansas                  762,166\n",
      "5             California               13,096,861\n",
      "6               Colorado                1,264,600\n",
      "7            Connecticut                  746,119\n",
      "8               Delaware                  227,909\n",
      "9   District of Columbia                  271,428\n",
      "10               Florida                3,808,334\n",
      "11               Georgia                1,990,810\n",
      "13                Hawaii                  340,513\n",
      "14                 Idaho                  283,355\n",
      "15              Illinois                3,269,999\n",
      "16               Indiana                1,295,358\n",
      "17                  Iowa                  618,505\n",
      "18                Kansas                  403,844\n",
      "19              Kentucky                1,284,193\n",
      "20             Louisiana                1,402,212\n",
      "21                 Maine                  288,324\n",
      "22              Maryland                1,271,445\n",
      "23         Massachusetts                1,829,618\n",
      "24              Michigan                3,947,031\n",
      "25             Minnesota                1,052,521\n",
      "26           Mississippi                  740,937\n",
      "27              Missouri                  944,257\n",
      "28               Montana                  139,950\n",
      "29              Nebraska                  239,463\n",
      "30                Nevada                  588,304\n",
      "31         New Hampshire                  186,399\n",
      "32            New Jersey                1,705,594\n",
      "33            New Mexico                  826,155\n",
      "34              New York                6,281,038\n",
      "35        North Carolina                1,965,805\n",
      "36          North Dakota                   86,250\n",
      "38                  Ohio                3,060,446\n",
      "39              Oklahoma                  829,561\n",
      "40                Oregon                1,123,913\n",
      "41          Pennsylvania                2,569,232\n",
      "42           Puerto Rico                1,458,819\n",
      "43          Rhode Island                  308,521\n",
      "44        South Carolina                1,233,430\n",
      "45          South Dakota                  124,497\n",
      "46             Tennessee                1,562,745\n",
      "47                 Texas                4,273,982\n",
      "48                  Utah                  293,867\n",
      "49               Vermont                  206,469\n",
      "51              Virginia                1,092,225\n",
      "52            Washington                1,771,679\n",
      "53         West Virginia                  545,748\n",
      "54             Wisconsin                1,209,714\n",
      "55               Wyoming                   66,532\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "#Notice: NaN can be either NaN or 'n/a'. Hence, we must take account all possible 'missing value' data\n",
    "print(medicaid_enrollment.loc[medicaid_enrollment[\"STATE\"] == \"Guam\"])\n",
    "medicaid_enrollment = medicaid_enrollment.dropna()\n",
    "\n",
    "medicaid_enrollment_cleaned = medicaid_enrollment.dropna()\n",
    "medicaid_enrollment_cleaned = medicaid_enrollment_cleaned[medicaid_enrollment_cleaned['STATE'] != 'Guam']\n",
    "print(medicaid_enrollment_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting `TOTAL MEDICAID ENROLLEE` Data Type\n",
    "\n",
    "* Given that data on `TOTAL MEDICAID ENROLLEE` column contains commas on file (ex. 3,269,999 instead of 3269999), `pandas` has erroneously set the data type for that column as a string. We need to convert the column from string to `int` since we will be using it in an arithmetic expression during normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        STATE  TOTAL MEDICAID ENROLLEES\n",
      "0     Alabama                   1050989\n",
      "1      Alaska                    164783\n",
      "3     Arizona                   1740520\n",
      "4    Arkansas                    762166\n",
      "5  California                  13096861\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "medicaid_enrollment_cleaned[\"TOTAL MEDICAID ENROLLEES\"] = medicaid_enrollment_cleaned[\"TOTAL MEDICAID ENROLLEES\"].apply(lambda x: int(x.replace(\",\", \"\")))\n",
    "print(medicaid_enrollment_cleaned.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inspect the `dtype` property of \"TOTAL MEDICAID ENROLLEES\" column, and make sure that the data type is `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('int64')"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "type(medicaid_enrollment_cleaned[\"TOTAL MEDICAID ENROLLEES\"])\n",
    "#dtype property\n",
    "medicaid_enrollment_cleaned[\"TOTAL MEDICAID ENROLLEES\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associating `medicaid_data` and `medicaid_enrollment_cleaned`\n",
    "\n",
    "* We can use the shared State information across both tables to associate both tables (SQL JOIN).\n",
    "\n",
    "* However, `medicaid_data` contains two-letter state abbreviations, while `medicaid_enrollment_cleaned` contains the complete state name\n",
    "\n",
    "  * We need to convert (or append) two-letter state abbreviations to `medicaid_enrollment_cleaned`\n",
    "\n",
    "* Pandas can read HTML and parse the code for tables. We will use that functionality to read in the state abbreviations from a Wikipedia page.\n",
    "\n",
    "  * A brief description of what the code does is included in the comments\n",
    "  \n",
    "* Note that the code below may throw an error if `lxml` is not installed on your machine. You should install any Python packages that Python complains about before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     US STATE POSTAL ABBREVIATION STANDARD ABBREVIATION\n0     Alabama                  AL                  Ala.\n1      Alaska                  AK                Alaska\n2     Arizona                  AZ                 Ariz.\n3    Arkansas                  AR                  Ark.\n4  California                  CA                Calif.",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>US STATE</th>\n      <th>POSTAL ABBREVIATION</th>\n      <th>STANDARD ABBREVIATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>AL</td>\n      <td>Ala.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alaska</td>\n      <td>AK</td>\n      <td>Alaska</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arizona</td>\n      <td>AZ</td>\n      <td>Ariz.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas</td>\n      <td>AR</td>\n      <td>Ark.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>CA</td>\n      <td>Calif.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.50states.com/abbreviations.htm'\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=header)\n",
    "\n",
    "tables = pd.read_html(r.text)\n",
    "\n",
    "\n",
    "# We access the desired table by giving it's index.\n",
    "# Since the URL contain only one table, then we can access that table using index 0\n",
    "Codes_abbreviations = tables[0]\n",
    "Codes_abbreviations.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the the `DataFrame`'s headers from ['US STATE',\t'POSTAL ABBREVIATION', \t'STANDARD ABBREVIATION'] to ['US STATE', 'ABBREVIATION', `STD ABBREVIATION`]\n",
    "  * You can hard code this operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     US STATE ABBREVIATION STD ABBREVIATION\n0     Alabama           AL             Ala.\n1      Alaska           AK           Alaska\n2     Arizona           AZ            Ariz.\n3    Arkansas           AR             Ark.\n4  California           CA           Calif.",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>US STATE</th>\n      <th>ABBREVIATION</th>\n      <th>STD ABBREVIATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>AL</td>\n      <td>Ala.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alaska</td>\n      <td>AK</td>\n      <td>Alaska</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arizona</td>\n      <td>AZ</td>\n      <td>Ariz.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas</td>\n      <td>AR</td>\n      <td>Ark.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>CA</td>\n      <td>Calif.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "Codes_abbreviations = Codes_abbreviations.rename({\"POSTAL ABBREVIATION\": \"ABBREVIATION\", \"STANDARD ABBREVIATION\": \"STD ABBREVIATION\"}, axis=1)\n",
    "Codes_abbreviations.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combine the tables `medicaid_enrollment_cleaned` and `Codes_abbreviations` such that the resulting `DataFrame` contains all the columns in `medicaid_enrollment_cleaned` and only `ABBREVIATION` from `Codes_abbreviations` \n",
    "\n",
    "* Save the results to a variable named `medicaid_enrollment_cleaned_with_zip`\n",
    "\n",
    "* `medicaid_enrollment_cleaned_with_zip` should look like the following ( '...' represents remaining data that is not shown):\n",
    "\n",
    "\n",
    "```\n",
    "   STATE    Total Medicaid Enrollees    ABBREVIATION\n",
    "0    Alabama    1,050,989    AL\n",
    "1    Alaska    164,783    AK\n",
    "2    Arizona    1,740,520    AZ\n",
    "3    Arkansas    762,166    AR\n",
    "4    California    13,096,861    CA\n",
    "...\n",
    "```\n",
    "\n",
    "* We did not cover joins in class -- you find a plethora of examples on how to do this online (e.g., `https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html`) and in a notebook under `Data Wrangling - Advanced` module. See for instance:\n",
    "\n",
    "\n",
    "* If you cannot get it to work, contact the `TA` for the solution. You will not be penalized if you don't answer this question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "merge() got multiple values for argument 'how'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-158-3f095a9b4e49>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#print(medicaid_enrollment_cleaned_with_zip)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mdfinal\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmedicaid_enrollment_cleaned\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmerge\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmedicaid_enrollment_cleaned\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mCodes_abbreviations\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mon\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"STATE\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhow\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'inner'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: merge() got multiple values for argument 'how'"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "#medicaid_enrollment_cleaned_with_zip = medicaid_enrollment_cleaned.merge(Codes_abbreviations, how=\"inner\", on=\"US STATE\")\n",
    "#print(medicaid_enrollment_cleaned_with_zip)\n",
    "\n",
    "dfinal = medicaid_enrollment_cleaned.merge(medicaid_enrollment_cleaned, Codes_abbreviations, on=\"STATE\", how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have no further use for the column STATE in  `medicaid_enrollment_cleaned_with_zip`\n",
    "\n",
    "  * Remove the column and make sure the data in `medicaid_enrollment_cleaned_with_zip` looks like the following  ( `...` represents remaining data that is not shown):\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "    Total Medicaid Enrollees    ABBREVIATION\n",
    "0   1,050,989                  AL\n",
    "1   164,783                    AK\n",
    "2   1,740,520                  AZ\n",
    "3   762,166                    AR\n",
    "4   13,096,861                 CA\n",
    "....\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n",
    "medicaid_enrollment_cleaned = medicaid_enrollment_cleaned.drop(columns=['STATE'],  axis=1)\n",
    "print(medicaid_enrollment_cleaned.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `DataFrame medicaid_enrollment_cleaned_with_zip` to assign the appropriate number of Medicaid enrollees to each entry in the `medicaid_data`\n",
    "\n",
    "   I.E., instead of the 10 original columns, `medicaid_data` will now have an 11th column representing the `TOTAL MEDICAID ENROLLEES` according to the STATE value in the entry.\n",
    "   \n",
    "- Save the resulting DataFrame into a new variable called `medicaid_data_w_enrollments`\n",
    "- The resulting DataFrame should look like the following (`...` represents remaining data that is not shown):\n",
    "\n",
    "```\n",
    "UTILIZATION TYPE    STATE    NDC    PRODUCT NAME    UNITS REIMBURSED    NUMBER OF PRESCRIPTIONS    TOTAL AMOUNT REIMBURSED    MEDICAID AMOUNT REIMBURSED    NON MEDICAID AMOUNT REIMBURSED    LOCATION\n",
    "0    MCOU    PA    55150023930    Dexamethas    33.0    19.0    234.98    234.98    0.0    (40.5773, -77.264)\n",
    "1    FFSU    NY    23917710    ALPHAGAN P    570.0    57.0    16006.34    16006.34    0.0    (42.1497, -74.9384)\n",
    "2    MCOU    OR    13925050501    Dapsone 10    456.0    15.0    1052.42    1052.42    0.0    (44.5672, -122.1269)\n",
    "...\n",
    "```\n",
    "\n",
    "* The order of the columns in the `DataFrame` is not relevant. This answer uses the same approach as the one used to `merge` the tables above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove any lines where \"STATE\" or \"PRODUCT NAME\" are missing from  `medicaid_data_w_enrollments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use [\"STATE\", \"PRODUCT NAME\"] as hierarchical index for `medicaid_data_w_enrollments`. Recall that a hierarchical index is simply an index with multiple levels of indexing (multiple columns)\n",
    "  * Hint: the function to set an index on a `DataFrame` can take a single column name or a list of column names. The list here is  [\"STATE\", \"NDC\"]\n",
    "- Call the new data `medicaid_data_w_enrollments_hierarch`\n",
    "- Inspect your data to make sure the new index has now two levels (STATE and NDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Write a single Pandas expression to print all the lines containing `NDC` `61958180101` in the Pennsylvania (\"PA\")\n",
    "\n",
    " * Use a single indexing call (bracket notation) using `loc`\n",
    " \n",
    " * Hint 1: Since your index is hierarchical, `loc` is expecting two values, the first for STATE and the second for NDC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the normalized `UNITS REIMBURSED` per drug \n",
    "\n",
    "\n",
    "\n",
    "* Compute the `UNITS REIMBURSED` for each \"NDC\" in each state normalized by the number of enrollees.\n",
    "\n",
    "\n",
    "\n",
    "- For instance in `PA`, the total `UNITS REIMBURSED` for the HARVONI `NDC` (61958180101) is 10,612\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "total_amount_reimbursed = medicaid_data_w_enrollments_hierarch.loc[(\"PA\", 61958180101), \"UNITS REIMBURSED\"].sum() \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- And the numebr of Medicaid Enrollees in \"PA\" is 2,569,232\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "total_enrollees_PA = medicaid_data_w_enrollments_hierarch.loc[\"PA\", \"TOTAL MEDICAID ENROLLEES\"].unique()[0]\n",
    "\n",
    "```\n",
    "\n",
    "- Therefore, the UNITS REIMBURSED per enrollee for \"HARVONI\" is  0.00413041718303\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "print(total_amount_reimbursed/total_enrollees_PA)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- Rather than work directly with the ratios, we are going to compute and work with their logarithm (np.log2) instead.\n",
    "\n",
    "\n",
    "\n",
    "  - The reason we use logs here is to avoid working small numbers. More on log-transformation in future lectures\n",
    "\n",
    "\n",
    "\n",
    "- Save the result in a `Series` called `medicaid_reimbursement_per_enrollee`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Your final result should be a `Series` that looks like the following ( `...` represents data that is not shown here):\n",
    "  * Note that negative values are the result of the `log` transformation \n",
    "\n",
    "```\n",
    "STATE  NDC    \n",
    "AK     2143380    -9.609109\n",
    "       2143480   -10.008280\n",
    "       2322730    -6.109830\n",
    "       2322830    -4.444321\n",
    "       2322930    -3.855995\n",
    "...\n",
    "AL     2143380    -9.940595\n",
    "       2143480    -9.805485\n",
    "       2322730    -5.336260\n",
    "...\n",
    "MA     2143380    -7.921997\n",
    "       2143480    -7.803463\n",
    "       2144511   -13.472194\n",
    "       2197590    -7.741402\n",
    "       2322730    -5.414724\n",
    "       2322830    -4.592154\n",
    "       2322930    -4.205626\n",
    "...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To facilitate working with the final data, we are going to unstack `medicaid_reimbursement_per_enrollee` into a variable called  `medicaid_norm_ndc`\n",
    "- Using `medicaid_reimbursement_per_enrollee`, generate a `DataFrame` where: \n",
    "  - `index` is the two-letter state symbol \n",
    "  - column names are the `NDC` codes \n",
    "- The `DataFrame` should be formatted as in the image below\n",
    "  - Hint: simply unstack the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/unstacked.png\" alt=\"drawing\" style=\"width:900px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the Data \n",
    "\n",
    "* What is the drug with the highest log-normalized ratio in Hawaii?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Investigate the NDC of the product with the highest log-normalized ratio in Hawaii \n",
    "  * What is it used for?\n",
    "\n",
    "* Compare the value of `Units Reimbursed` that product between HI and other states, (take for instance MA, FL, OR and WA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you think for reasons why this product has the highest log-normalized ratio in Hawaii? (Not graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR ANSWER HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find and list all unique `NDC`s for which the difference between the largest and second large log-scale ratio-by-state is at least 10.\n",
    "\n",
    "* For instance:\n",
    "  * The highest log-normalized ratio for `00591289749` (`AZACITIDIN`) is OK where it has a log-normalized ratio of `-1.025642`.\n",
    "  * The second highest log-normalized ratio for `00591289749` is in `GA` where is has a log-normalized ratio of  `-12.623428`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Drug `AZACITIDINE` has a very high normalized UNITS REIMBURSED in OK compared to other states\n",
    "   * Normalized log value is -1.025642 (or a ratio 0.49119167009735065)\n",
    "   * The second highest state has a log value of -12.623428 (0.000158478197834722)\n",
    "* Oklahoma is not a high-incidence state for cancer\n",
    "* Could the following explain what is happening in Oklahoma?\n",
    "  * The following is clinical trial conducted by the University of Oklahoma\n",
    "\n",
    "https://www.centerwatch.com/clinical-trials/listings/92093/acute-myeloid-leukemia-aml-study-asp2215-gilteritinib-by/?&geo_lat=35.4675602&geo_lng=-97.5164276&radius=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}